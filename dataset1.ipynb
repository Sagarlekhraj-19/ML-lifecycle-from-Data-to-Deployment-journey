{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71c5f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING DATASET\n",
      "============================================================\n",
      "‚úì Dataset loaded successfully!\n",
      "‚úì Shape: 7043 rows √ó 21 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# TELCO CUSTOMER CHURN - COMPLETE DATA ANALYSIS\n",
    "# =====================================================\n",
    "# Dataset: Telco Customer Churn Data\n",
    "# Purpose: Data Loading, Cleaning, and Preparation\n",
    "# =====================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# =====================================================\n",
    "# 1. LOAD DATA\n",
    "# =====================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "df_original = df.copy()  # Keep original for comparison\n",
    "\n",
    "print(f\"‚úì Dataset loaded successfully!\")\n",
    "print(f\"‚úì Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba52bf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET PREVIEW (First 5 Rows)\n",
      "============================================================\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "============================================================\n",
      "DATASET INFORMATION\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n",
      "\n",
      "============================================================\n",
      "STATISTICAL SUMMARY\n",
      "============================================================\n",
      "       SeniorCitizen       tenure  MonthlyCharges\n",
      "count    7043.000000  7043.000000     7043.000000\n",
      "mean        0.162147    32.371149       64.761692\n",
      "std         0.368612    24.559481       30.090047\n",
      "min         0.000000     0.000000       18.250000\n",
      "25%         0.000000     9.000000       35.500000\n",
      "50%         0.000000    29.000000       70.350000\n",
      "75%         0.000000    55.000000       89.850000\n",
      "max         1.000000    72.000000      118.750000\n",
      "\n",
      "============================================================\n",
      "COLUMN NAMES\n",
      "============================================================\n",
      " 1. customerID\n",
      " 2. gender\n",
      " 3. SeniorCitizen\n",
      " 4. Partner\n",
      " 5. Dependents\n",
      " 6. tenure\n",
      " 7. PhoneService\n",
      " 8. MultipleLines\n",
      " 9. InternetService\n",
      "10. OnlineSecurity\n",
      "11. OnlineBackup\n",
      "12. DeviceProtection\n",
      "13. TechSupport\n",
      "14. StreamingTV\n",
      "15. StreamingMovies\n",
      "16. Contract\n",
      "17. PaperlessBilling\n",
      "18. PaymentMethod\n",
      "19. MonthlyCharges\n",
      "20. TotalCharges\n",
      "21. Churn\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 2. INITIAL DATA EXPLORATION\n",
    "# =====================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET PREVIEW (First 5 Rows)\")\n",
    "print(\"=\"*60)\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLUMN NAMES\")\n",
    "print(\"=\"*60)\n",
    "for idx, col in enumerate(df.columns, 1):\n",
    "    print(f\"{idx:2d}. {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75df3179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Saved: first_5_rows.png\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 3. VISUALIZATION: FIRST 5 ROWS\n",
    "# =====================================================\n",
    "\n",
    "def visualize_first_rows(dataframe, n=5):\n",
    "    \"\"\"Create a clean table visualization of first n rows\"\"\"\n",
    "    \n",
    "    first_n = dataframe.head(n)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 4))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table = ax.table(\n",
    "        cellText=first_n.values,\n",
    "        colLabels=first_n.columns,\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        bbox=[0, 0, 1, 1]\n",
    "    )\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2.5)\n",
    "    \n",
    "    # Style header\n",
    "    for i in range(len(first_n.columns)):\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Style rows with alternating colors\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(len(first_n.columns)):\n",
    "            table[(i, j)].set_facecolor('#f9f9f9' if i % 2 == 0 else 'white')\n",
    "    \n",
    "    plt.savefig('first_5_rows.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(\"\\n‚úì Saved: first_5_rows.png\")\n",
    "    plt.close()\n",
    "\n",
    "visualize_first_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a477a90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved: column_names.png\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 4. VISUALIZATION: COLUMN NAMES\n",
    "# =====================================================\n",
    "\n",
    "def visualize_column_names(dataframe):\n",
    "    \"\"\"Create a styled list of all column names\"\"\"\n",
    "    \n",
    "    columns = dataframe.columns.tolist()\n",
    "    num_columns = len(columns)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, max(8, num_columns * 0.4)))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Title\n",
    "    plt.text(0.5, 0.95, f'Dataset Columns ({num_columns} total)', \n",
    "             ha='center', va='top', fontsize=18, fontweight='bold',\n",
    "             transform=ax.transAxes)\n",
    "    \n",
    "    # Create column list layout\n",
    "    y_start = 0.88\n",
    "    y_step = 0.85 / num_columns\n",
    "    \n",
    "    for idx, col in enumerate(columns):\n",
    "        y_pos = y_start - (idx * y_step)\n",
    "        \n",
    "        # Styled box for each column\n",
    "        rect = mpatches.FancyBboxPatch(\n",
    "            (0.05, y_pos - 0.015), 0.9, 0.03,\n",
    "            boxstyle=\"round,pad=0.01\",\n",
    "            facecolor='#4CAF50' if idx % 2 == 0 else '#66BB6A',\n",
    "            edgecolor='#2E7D32',\n",
    "            transform=ax.transAxes,\n",
    "            linewidth=1.5\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Column number and name\n",
    "        plt.text(0.08, y_pos, f\"{idx + 1}.\", \n",
    "                 ha='left', va='center', fontsize=11, fontweight='bold',\n",
    "                 color='white', transform=ax.transAxes)\n",
    "        \n",
    "        plt.text(0.13, y_pos, col, \n",
    "                 ha='left', va='center', fontsize=11,\n",
    "                 color='white', transform=ax.transAxes)\n",
    "    \n",
    "    # Footer\n",
    "    plt.text(0.5, 0.02, f'Total Features: {num_columns}', \n",
    "             ha='center', va='bottom', fontsize=10, style='italic',\n",
    "             transform=ax.transAxes, color='#555')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('column_names.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(\"‚úì Saved: column_names.png\")\n",
    "    plt.close()\n",
    "\n",
    "visualize_column_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0c569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MISSING VALUES SUMMARY\n",
      "============================================================\n",
      "Total Rows: 7043\n",
      "Total Columns: 21\n",
      "Columns with Missing Values: 0\n",
      "\n",
      "‚úì No missing values detected!\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 5. MISSING VALUES ANALYSIS\n",
    "# =====================================================\n",
    "\n",
    "def analyze_missing_values(dataframe):\n",
    "    \"\"\"Comprehensive missing values analysis\"\"\"\n",
    "    \n",
    "    missing_data = pd.DataFrame({\n",
    "        'Column': dataframe.columns,\n",
    "        'Missing_Count': dataframe.isnull().sum(),\n",
    "        'Missing_Percentage': (dataframe.isnull().sum() / len(dataframe)) * 100,\n",
    "        'Data_Type': dataframe.dtypes.astype(str)\n",
    "    })\n",
    "    \n",
    "    missing_data = missing_data.sort_values('Missing_Percentage', ascending=False)\n",
    "    missing_data_filtered = missing_data[missing_data['Missing_Count'] > 0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MISSING VALUES SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Rows: {len(dataframe)}\")\n",
    "    print(f\"Total Columns: {len(dataframe.columns)}\")\n",
    "    print(f\"Columns with Missing Values: {len(missing_data_filtered)}\")\n",
    "    \n",
    "    if len(missing_data_filtered) > 0:\n",
    "        print(\"\\nMissing Values Details:\")\n",
    "        print(missing_data_filtered.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\n‚úì No missing values detected!\")\n",
    "    \n",
    "    return missing_data_filtered\n",
    "\n",
    "missing_values = analyze_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3edb8135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Saved: missing_values_analysis.png\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 6. VISUALIZATION: MISSING VALUES\n",
    "# =====================================================\n",
    "\n",
    "def visualize_missing_values(dataframe, missing_df):\n",
    "    \"\"\"Create comprehensive missing values visualization\"\"\"\n",
    "    \n",
    "    if len(missing_df) == 0:\n",
    "        # No missing values - success message\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.axis('off')\n",
    "        \n",
    "        plt.text(0.5, 0.5, '‚úì NO MISSING VALUES FOUND!', \n",
    "                 ha='center', va='center', fontsize=24, fontweight='bold',\n",
    "                 color='#27ae60', transform=ax.transAxes)\n",
    "        \n",
    "        plt.text(0.5, 0.3, f'All {len(dataframe.columns)} columns are complete', \n",
    "                 ha='center', va='center', fontsize=14,\n",
    "                 color='#555', transform=ax.transAxes)\n",
    "        \n",
    "        plt.savefig('missing_values_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        print(\"\\n‚úì Saved: missing_values_analysis.png\")\n",
    "        plt.close()\n",
    "        return\n",
    "    \n",
    "    # Create dual visualization for missing values\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, max(6, len(missing_df) * 0.5)))\n",
    "    \n",
    "    # Color coding by severity\n",
    "    colors = [\n",
    "        '#e74c3c' if x > 50 else '#f39c12' if x > 20 else '#3498db'\n",
    "        for x in missing_df['Missing_Percentage']\n",
    "    ]\n",
    "    \n",
    "    # Left: Horizontal bar chart\n",
    "    bars = ax1.barh(\n",
    "        missing_df['Column'],\n",
    "        missing_df['Missing_Percentage'],\n",
    "        color=colors,\n",
    "        edgecolor='black',\n",
    "        linewidth=1.2\n",
    "    )\n",
    "    \n",
    "    ax1.set_xlabel('Missing Percentage (%)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Columns', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Missing Values by Column', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    ax1.set_xlim(0, 100)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for bar, pct in zip(bars, missing_df['Missing_Percentage']):\n",
    "        ax1.text(\n",
    "            bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "            f'{pct:.2f}%',\n",
    "            ha='left', va='center', fontsize=9, fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    # Right: Detailed table\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        [row['Column'], f\"{int(row['Missing_Count'])}\", \n",
    "         f\"{row['Missing_Percentage']:.2f}%\", str(row['Data_Type'])]\n",
    "        for _, row in missing_df.head(15).iterrows()\n",
    "    ]\n",
    "    \n",
    "    table = ax2.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=['Column', 'Count', 'Missing %', 'Type'],\n",
    "        cellLoc='left',\n",
    "        loc='center',\n",
    "        bbox=[0, 0, 1, 1]\n",
    "    )\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Style header\n",
    "    for i in range(4):\n",
    "        table[(0, i)].set_facecolor('#e74c3c')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Style rows with color coding\n",
    "    for i in range(1, len(table_data) + 1):\n",
    "        pct = float(table_data[i-1][2].strip('%'))\n",
    "        color = '#ffcccc' if pct > 50 else '#ffe6cc' if pct > 20 else '#cce6ff'\n",
    "        for j in range(4):\n",
    "            table[(i, j)].set_facecolor(color)\n",
    "    \n",
    "    ax2.set_title('Missing Values Details', fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    fig.suptitle(\n",
    "        f'Missing Values Analysis - {len(missing_df)} Columns Affected',\n",
    "        fontsize=16, fontweight='bold', y=0.98\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('missing_values_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(\"\\n‚úì Saved: missing_values_analysis.png\")\n",
    "    plt.close()\n",
    "\n",
    "visualize_missing_values(df, missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d76ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA TYPES SUMMARY\n",
      "============================================================\n",
      "          Column Data_Type\n",
      "      customerID    object\n",
      "          gender    object\n",
      "   SeniorCitizen     int64\n",
      "         Partner    object\n",
      "      Dependents    object\n",
      "          tenure     int64\n",
      "    PhoneService    object\n",
      "   MultipleLines    object\n",
      " InternetService    object\n",
      "  OnlineSecurity    object\n",
      "    OnlineBackup    object\n",
      "DeviceProtection    object\n",
      "     TechSupport    object\n",
      "     StreamingTV    object\n",
      " StreamingMovies    object\n",
      "        Contract    object\n",
      "PaperlessBilling    object\n",
      "   PaymentMethod    object\n",
      "  MonthlyCharges   float64\n",
      "    TotalCharges    object\n",
      "           Churn    object\n",
      "\n",
      "============================================================\n",
      "DATA TYPE DISTRIBUTION\n",
      "============================================================\n",
      "object          : 18 columns\n",
      "int64           : 2 columns\n",
      "float64         : 1 columns\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 7. DATA TYPES ANALYSIS\n",
    "# =====================================================\n",
    "\n",
    "def analyze_data_types(dataframe):\n",
    "    \"\"\"Analyze and visualize data types distribution\"\"\"\n",
    "    \n",
    "    dtype_df = pd.DataFrame({\n",
    "        \"Column\": dataframe.columns,\n",
    "        \"Data_Type\": dataframe.dtypes.astype(str)\n",
    "    })\n",
    "    \n",
    "    dtype_counts = dtype_df[\"Data_Type\"].value_counts()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA TYPES SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(dtype_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA TYPE DISTRIBUTION\")\n",
    "    print(\"=\"*60)\n",
    "    for dtype, count in dtype_counts.items():\n",
    "        print(f\"{dtype:15s} : {count} columns\")\n",
    "    \n",
    "    return dtype_df, dtype_counts\n",
    "\n",
    "dtype_info, dtype_distribution = analyze_data_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e6ddfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Saved: data_types_analysis.png\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 8. VISUALIZATION: DATA TYPES\n",
    "# =====================================================\n",
    "\n",
    "def visualize_data_types(dtype_df, dtype_counts):\n",
    "    \"\"\"Create comprehensive data types visualization\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        1, 2, figsize=(18, max(8, len(dtype_df) * 0.4))\n",
    "    )\n",
    "    \n",
    "    # Left: Table of all columns with their types\n",
    "    ax1.axis('off')\n",
    "    table = ax1.table(\n",
    "        cellText=dtype_df.values.tolist(),\n",
    "        colLabels=[\"Column Name\", \"Data Type\"],\n",
    "        cellLoc='left',\n",
    "        loc='center',\n",
    "        bbox=[0, 0, 1, 1]\n",
    "    )\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 1.5)\n",
    "    \n",
    "    # Style header\n",
    "    for col in range(2):\n",
    "        table[(0, col)].set_facecolor('#34495e')\n",
    "        table[(0, col)].set_text_props(color='white', weight='bold')\n",
    "    \n",
    "    # Style rows\n",
    "    for i in range(1, len(dtype_df) + 1):\n",
    "        for j in range(2):\n",
    "            table[(i, j)].set_facecolor('#ecf0f1')\n",
    "    \n",
    "    ax1.set_title(\"Column Data Types\", fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Right: Bar chart of type distribution\n",
    "    colors_palette = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "    bars = ax2.bar(\n",
    "        range(len(dtype_counts)),\n",
    "        dtype_counts.values,\n",
    "        color=colors_palette[:len(dtype_counts)],\n",
    "        edgecolor='black',\n",
    "        linewidth=1.2\n",
    "    )\n",
    "    \n",
    "    ax2.set_xticks(range(len(dtype_counts)))\n",
    "    ax2.set_xticklabels(dtype_counts.index, rotation=45, ha='right')\n",
    "    ax2.set_title(\"Data Type Distribution\", fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel(\"Data Type\", fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel(\"Number of Columns\", fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(\n",
    "            bar.get_x() + bar.get_width()/2, height,\n",
    "            int(height), ha='center', va='bottom',\n",
    "            fontsize=10, fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    fig.suptitle(\n",
    "        f\"Data Types Analysis ({len(dtype_df)} Columns)\",\n",
    "        fontsize=16, fontweight='bold', y=0.98\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data_types_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(\"\\n‚úì Saved: data_types_analysis.png\")\n",
    "    plt.close()\n",
    "\n",
    "visualize_data_types(dtype_info, dtype_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae997fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA CLEANING\n",
      "============================================================\n",
      "Duplicate rows: 0\n",
      "\n",
      "‚ö† Found 'TotalCharges' as object type - converting to numeric\n",
      "‚úì Converted 'TotalCharges' to numeric\n",
      "‚úì Filled 11 missing values in 'TotalCharges' with median\n",
      "\n",
      "‚úì Data cleaning completed!\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 9. DATA CLEANING (IF NEEDED)\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA CLEANING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Since this dataset has no missing values, we'll check for other issues\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"‚úì Removed {duplicates} duplicate rows\")\n",
    "\n",
    "# Check for any data quality issues\n",
    "# Example: Check if TotalCharges is object type (should be numeric)\n",
    "if df['TotalCharges'].dtype == 'object':\n",
    "    print(\"\\n‚ö† Found 'TotalCharges' as object type - converting to numeric\")\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    print(\"‚úì Converted 'TotalCharges' to numeric\")\n",
    "    \n",
    "    # Fill any NaN created during conversion\n",
    "    if df['TotalCharges'].isnull().any():\n",
    "        missing_count = df['TotalCharges'].isnull().sum()\n",
    "        df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "        print(f\"‚úì Filled {missing_count} missing values in 'TotalCharges' with median\")\n",
    "\n",
    "print(\"\\n‚úì Data cleaning completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4945cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING CLEANED DATA\n",
      "============================================================\n",
      "‚úì Saved: telco_customer_churn_cleaned.csv\n",
      "\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "Original Shape    : (7043, 21)\n",
      "Cleaned Shape     : (7043, 21)\n",
      "Rows Removed      : 0\n",
      "Columns Removed   : 0\n",
      "Missing Values    : 0\n",
      "Duplicate Rows    : 0\n",
      "\n",
      "‚úì Data analysis and cleaning completed successfully!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "FILES CREATED\n",
      "============================================================\n",
      "1. first_5_rows.png              - Visual preview of data\n",
      "2. column_names.png              - List of all columns\n",
      "3. missing_values_analysis.png   - Missing values report\n",
      "4. data_types_analysis.png       - Data types distribution\n",
      "5. telco_customer_churn_cleaned.csv - Cleaned dataset\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 10. SAVE CLEANED DATA\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING CLEANED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df.to_csv('telco_customer_churn_cleaned.csv', index=False)\n",
    "print(\"‚úì Saved: telco_customer_churn_cleaned.csv\")\n",
    "\n",
    "# =====================================================\n",
    "# 11. FINAL SUMMARY\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original Shape    : {df_original.shape}\")\n",
    "print(f\"Cleaned Shape     : {df.shape}\")\n",
    "print(f\"Rows Removed      : {df_original.shape[0] - df.shape[0]}\")\n",
    "print(f\"Columns Removed   : {df_original.shape[1] - df.shape[1]}\")\n",
    "print(f\"Missing Values    : {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate Rows    : {df.duplicated().sum()}\")\n",
    "print(f\"\\n‚úì Data analysis and cleaning completed successfully!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FILES CREATED\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. first_5_rows.png              - Visual preview of data\")\n",
    "print(\"2. column_names.png              - List of all columns\")\n",
    "print(\"3. missing_values_analysis.png   - Missing values report\")\n",
    "print(\"4. data_types_analysis.png       - Data types distribution\")\n",
    "print(\"5. telco_customer_churn_cleaned.csv - Cleaned dataset\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "136f341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 1: TRAIN-TEST SPLIT\n",
      "================================================================================\n",
      "\n",
      "Note: Creating synthetic target for demonstration\n",
      "\n",
      "Original Dataset Shape: (7043, 22)\n",
      "Features Shape: (7043, 21)\n",
      "Target Shape: (7043,)\n",
      "\n",
      "Train Set Size: 5634 samples (80.0%)\n",
      "Test Set Size: 1409 samples (20.0%)\n",
      "\n",
      "Target Distribution in Train Set:\n",
      "target\n",
      "0    2860\n",
      "1    2774\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target Distribution in Test Set:\n",
      "target\n",
      "0    715\n",
      "1    694\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# ============================================================================\n",
    "# STEP 1: TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Assuming 'target' is your target variable - adjust as needed\n",
    "# For demonstration, let's create a synthetic target if not exists\n",
    "if 'target' not in df.columns:\n",
    "    print(\"\\nNote: Creating synthetic target for demonstration\")\n",
    "    df['target'] = np.random.choice([0, 1], size=len(df))\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"\\nOriginal Dataset Shape: {df.shape}\")\n",
    "print(f\"Features Shape: {X.shape}\")\n",
    "print(f\"Target Shape: {y.shape}\")\n",
    "\n",
    "# Perform train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain Set Size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test Set Size: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTarget Distribution in Train Set:\\n{y_train.value_counts()}\")\n",
    "print(f\"\\nTarget Distribution in Test Set:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "430fe440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: 16 | Numerical: 4\n",
      "üìä Label: gender\n",
      "üìä Label: Partner\n",
      "üìä Label: Dependents\n",
      "üìä Label: PhoneService\n",
      "üî¢ OneHot: MultipleLines (3 cats)\n",
      "üî¢ OneHot: InternetService (3 cats)\n",
      "üî¢ OneHot: OnlineSecurity (3 cats)\n",
      "üî¢ OneHot: OnlineBackup (3 cats)\n",
      "üî¢ OneHot: DeviceProtection (3 cats)\n",
      "üî¢ OneHot: TechSupport (3 cats)\n",
      "üî¢ OneHot: StreamingTV (3 cats)\n",
      "üî¢ OneHot: StreamingMovies (3 cats)\n",
      "üî¢ OneHot: Contract (3 cats)\n",
      "üìä Label: PaperlessBilling\n",
      "üî¢ OneHot: PaymentMethod (4 cats)\n",
      "üìä Label: Churn\n",
      "\n",
      "üéØ Target classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================\n",
    "# CONFIGURATION\n",
    "# ==============================\n",
    "ID_THRESHOLD = 0.95\n",
    "LOW_CARDINALITY_THRESHOLD = 10\n",
    "\n",
    "# ==============================\n",
    "# STEP 1: Identify columns\n",
    "# ==============================\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical: {len(categorical_cols)} | Numerical: {len(numerical_cols)}\")\n",
    "\n",
    "# ==============================\n",
    "# STEP 2: Drop ID columns\n",
    "# ==============================\n",
    "id_columns = [col for col in categorical_cols \n",
    "              if X_train[col].nunique() / len(X_train) > ID_THRESHOLD]\n",
    "\n",
    "if id_columns:\n",
    "    print(f\"\\nüóëÔ∏è  Dropping ID columns: {id_columns}\")\n",
    "    X_train = X_train.drop(columns=id_columns)\n",
    "    X_test = X_test.drop(columns=id_columns)\n",
    "    categorical_cols = [c for c in categorical_cols if c not in id_columns]\n",
    " \n",
    "\n",
    "# ==============================\n",
    "# STEP 4: Encode categorical\n",
    "# ==============================\n",
    "encoders = {}\n",
    "metadata = {'binary': [], 'onehot': [], 'frequency': []}\n",
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    n_unique = X_train[col].nunique()\n",
    "    \n",
    "    if n_unique == 2:\n",
    "        print(f\"üìä Label: {col}\")\n",
    "        le = LabelEncoder()\n",
    "        X_train_encoded[col] = le.fit_transform(X_train[col].astype(str))\n",
    "        \n",
    "        # Robust test encoding\n",
    "        X_test_encoded[col] = X_test[col].astype(str).map(\n",
    "            {cls: idx for idx, cls in enumerate(le.classes_)}\n",
    "        ).fillna(0).astype(int)\n",
    "        \n",
    "        encoders[col] = ('label', le)\n",
    "        metadata['binary'].append(col)\n",
    "    \n",
    "    elif n_unique <= LOW_CARDINALITY_THRESHOLD:\n",
    "        print(f\"üî¢ OneHot: {col} ({n_unique} cats)\")\n",
    "        ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        \n",
    "        train_enc = ohe.fit_transform(X_train[[col]])\n",
    "        test_enc = ohe.transform(X_test[[col]])\n",
    "        \n",
    "        cols_names = [f\"{col}_{cat}\" for cat in ohe.categories_[0]]\n",
    "        train_df = pd.DataFrame(train_enc, columns=cols_names, index=X_train.index)\n",
    "        test_df = pd.DataFrame(test_enc, columns=cols_names, index=X_test.index)\n",
    "        \n",
    "        X_train_encoded = pd.concat([X_train_encoded.drop(col, axis=1), train_df], axis=1)\n",
    "        X_test_encoded = pd.concat([X_test_encoded.drop(col, axis=1), test_df], axis=1)\n",
    "        \n",
    "        encoders[col] = ('onehot', ohe)\n",
    "        metadata['onehot'].append(col)\n",
    "    \n",
    "    else:\n",
    "        print(f\"üìà Frequency: {col} ({n_unique} cats)\")\n",
    "        freq_map = X_train[col].value_counts(normalize=True).to_dict()\n",
    "        min_freq = min(freq_map.values()) if freq_map else 0.0001\n",
    "        \n",
    "        X_train_encoded[col] = X_train[col].map(freq_map)\n",
    "        X_test_encoded[col] = X_test[col].map(freq_map).fillna(min_freq)\n",
    "        \n",
    "        encoders[col] = ('frequency', freq_map)\n",
    "        metadata['frequency'].append(col)\n",
    "\n",
    "# ==============================\n",
    "# STEP 5: Encode target\n",
    "# ==============================\n",
    "target_le = LabelEncoder()\n",
    "y_train_encoded = target_le.fit_transform(y_train)\n",
    "y_test_encoded = target_le.transform(y_test)\n",
    "encoders['target'] = ('label', target_le)\n",
    "\n",
    "print(f\"\\nüéØ Target classes: {target_le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef7546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5634, 41)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f286c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
